{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import math\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# tf.keras.backend.floatx()\n",
    "# import pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR=\"D:\\Codes\\Image-Classification\\cardataset/train\"\n",
    "VALIDATION_DATA_DIR=\"D:\\Codes\\Image-Classification\\cardataset/val\"\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 17\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(#preprocessing_function=preprocessing,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator()#preprocessing_function=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22852 images belonging to 17 classes.\n",
      "Found 5193 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = EfficientNetB0(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    # x=tf.cast(input,tf.float32)\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 30s 2s/step - loss: 2.3856 - acc: 0.3030 - val_loss: 1.8667 - val_acc: 0.5547\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 27s 1s/step - loss: 2.0826 - acc: 0.3845 - val_loss: 1.9216 - val_acc: 0.4121\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 28s 2s/step - loss: 1.8272 - acc: 0.4323 - val_loss: 1.7211 - val_acc: 0.5215\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 27s 2s/step - loss: 1.9117 - acc: 0.4470 - val_loss: 1.5001 - val_acc: 0.5977\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 38s 2s/step - loss: 1.8492 - acc: 0.4227 - val_loss: 1.6345 - val_acc: 0.5742\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 38s 2s/step - loss: 1.6948 - acc: 0.4618 - val_loss: 1.5397 - val_acc: 0.5879\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 39s 2s/step - loss: 1.7222 - acc: 0.4809 - val_loss: 1.6577 - val_acc: 0.5645\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 1.7708 - acc: 0.4635 - val_loss: 1.6098 - val_acc: 0.5938\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 1.6014 - acc: 0.4931 - val_loss: 1.7022 - val_acc: 0.5039\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 35s 2s/step - loss: 1.6359 - acc: 0.4974 - val_loss: 1.5540 - val_acc: 0.5879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0042a7a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_maker()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['acc'])\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(18),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ambulance',\n",
       " 'Barge',\n",
       " 'Bicycle',\n",
       " 'Boat',\n",
       " 'Bus',\n",
       " 'Car',\n",
       " 'Cart',\n",
       " 'Caterpillar',\n",
       " 'Helicopter',\n",
       " 'Limousine',\n",
       " 'Motorcycle',\n",
       " 'Segway',\n",
       " 'Snowmobile',\n",
       " 'Tank',\n",
       " 'Taxi',\n",
       " 'Truck',\n",
       " 'Van']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=list((validation_generator.class_indices).keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_MobileNet_preprocess\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_EfficientNetB0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "model= tf.keras.models.load_model(\"D:\\Codes\\Image-Classification\\model_EfficientNetB0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.155386"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"D:\\Codes\\Image-Classification/airbus-helicopters-4-gq-3jun15-pr_b.jpg\" #bike\n",
    "# img_path='D:\\Codes\\Image-Classification\\elantra-1080p.jpg' #elantra\n",
    "# img=image.load_img(img_path)\n",
    " \n",
    "img = tf.io.read_file(img_path)\n",
    "img = tf.image.decode_jpeg(img)\n",
    "img = tf.image.resize(img, [224,224])\n",
    "# img=preprocess_input(img)\n",
    "img= tf.cast(tf.expand_dims(img, axis=0), tf.int16)\n",
    "#  \n",
    " \n",
    "# img = tf.image.decode_jpeg(img)\n",
    "# img = tf.image.resize(img, [224,224])\n",
    "# img= tf.expand_dims(img, axis=0)\n",
    "# img=tf.cast(img, tf.int16)\n",
    "# img=preprocess_input(img)\n",
    "  \n",
    "\n",
    "prediction=model.predict(img)\n",
    "\n",
    "\n",
    "\n",
    "class_names[tf.argmax(prediction[0])]\n",
    "(tf.reduce_max(prediction)*100).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[104  88  56]\n",
      "   [106  94  62]\n",
      "   [110  99  58]\n",
      "   ...\n",
      "   [115 106  92]\n",
      "   [111 104  85]\n",
      "   [110 102  80]]\n",
      "\n",
      "  [[115 100  64]\n",
      "   [119 102  68]\n",
      "   [132 112  75]\n",
      "   ...\n",
      "   [110 102  83]\n",
      "   [112 106  82]\n",
      "   [102  97  81]]\n",
      "\n",
      "  [[125 111  69]\n",
      "   [135 117  79]\n",
      "   [140 120  85]\n",
      "   ...\n",
      "   [ 80  77  68]\n",
      "   [ 83  81  70]\n",
      "   [ 74  74  67]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 40  49  21]\n",
      "   [ 72  84  43]\n",
      "   [ 33  40  24]\n",
      "   ...\n",
      "   [ 26  41  41]\n",
      "   [ 21  36  32]\n",
      "   [ 36  45  35]]\n",
      "\n",
      "  [[ 59  71  34]\n",
      "   [ 50  67  15]\n",
      "   [ 37  45  28]\n",
      "   ...\n",
      "   [ 30  41  39]\n",
      "   [ 45  54  43]\n",
      "   [ 61  66  46]]\n",
      "\n",
      "  [[ 68  81  43]\n",
      "   [ 46  58  21]\n",
      "   [ 37  47  20]\n",
      "   ...\n",
      "   [ 36  43  38]\n",
      "   [ 60  70  49]\n",
      "   [ 73  75  58]]]], shape=(1, 224, 224, 3), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "print(img\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Ambulance', 'Barge', 'Bicycle', 'Boat', 'Bus', 'Car', 'Cart', 'Caterpillar', 'Helicopter', 'Limousine', 'Motorcycle', 'Segway', 'Snowmobile', 'Tank', 'Taxi', 'Truck', 'Van'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "def make_prediction(img):#,class_names):\n",
    "    img=image.load_img(img, target_size=(224,224))\n",
    "\n",
    "    img_array = image.img_to_array(img)\n",
    "    expand_img_array=np.expand_dims(img_array, axis=0)\n",
    "    # preprocessed_img=preprocess_input(expand_img_array\n",
    "\n",
    "    prediction=model.predict(preprocessed_img)\n",
    "\n",
    "\n",
    "    pred_prob=class_names[tf.argmax(prediction[0])]\n",
    "    pred_class=(tf.reduce_max(prediction)*100).numpy()\n",
    "    return pred_class, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"D:\\Codes\\Image-Classification\\elantra-1080p.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/3022437414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15608/1103276651.py\u001b[0m in \u001b[0;36mmake_prediction\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# preprocessed_img=preprocess_input(expand_img_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_img' is not defined"
     ]
    }
   ],
   "source": [
    "make_prediction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ce94f09205e5177e121f09cd120bc377f4c139dc7d85c3df6c5c29ddd26d191"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
